{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[01:38:25] /Users/travis/build/dmlc/xgboost/include/xgboost/json.h:65: Invalid cast, from Null to Array\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000011f68c1c0 dmlc::LogMessageFatal::~LogMessageFatal() + 112\n  [bt] (1) 2   libxgboost.dylib                    0x000000011f6cab63 xgboost::JsonArray const* xgboost::Cast<xgboost::JsonArray const, xgboost::Value>(xgboost::Value*) + 739\n  [bt] (2) 3   libxgboost.dylib                    0x000000011f79531f xgboost::RegTree::LoadModel(xgboost::Json const&) + 1519\n  [bt] (3) 4   libxgboost.dylib                    0x000000011f724954 xgboost::gbm::GBTreeModel::LoadModel(xgboost::Json const&) + 548\n  [bt] (4) 5   libxgboost.dylib                    0x000000011f714b53 xgboost::gbm::GBTree::LoadModel(xgboost::Json const&) + 419\n  [bt] (5) 6   libxgboost.dylib                    0x000000011f72716d xgboost::LearnerIO::LoadModel(xgboost::Json const&) + 2173\n  [bt] (6) 7   libxgboost.dylib                    0x000000011f72fe98 xgboost::LearnerIO::Load(dmlc::Stream*) + 408\n  [bt] (7) 8   libxgboost.dylib                    0x000000011f687b78 XGBoosterUnserializeFromBuffer + 168\n  [bt] (8) 9   _ctypes.cpython-37m-darwin.so       0x0000000103d81177 ffi_call_unix64 + 79\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-06446fb84bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Montreal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_vars\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../models/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".dat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0mptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             _check_call(\n\u001b[0;32m-> 1212\u001b[0;31m                 _LIB.XGBoosterUnserializeFromBuffer(handle, ptr, length))\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'handle'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [01:38:25] /Users/travis/build/dmlc/xgboost/include/xgboost/json.h:65: Invalid cast, from Null to Array\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000011f68c1c0 dmlc::LogMessageFatal::~LogMessageFatal() + 112\n  [bt] (1) 2   libxgboost.dylib                    0x000000011f6cab63 xgboost::JsonArray const* xgboost::Cast<xgboost::JsonArray const, xgboost::Value>(xgboost::Value*) + 739\n  [bt] (2) 3   libxgboost.dylib                    0x000000011f79531f xgboost::RegTree::LoadModel(xgboost::Json const&) + 1519\n  [bt] (3) 4   libxgboost.dylib                    0x000000011f724954 xgboost::gbm::GBTreeModel::LoadModel(xgboost::Json const&) + 548\n  [bt] (4) 5   libxgboost.dylib                    0x000000011f714b53 xgboost::gbm::GBTree::LoadModel(xgboost::Json const&) + 419\n  [bt] (5) 6   libxgboost.dylib                    0x000000011f72716d xgboost::LearnerIO::LoadModel(xgboost::Json const&) + 2173\n  [bt] (6) 7   libxgboost.dylib                    0x000000011f72fe98 xgboost::LearnerIO::Load(dmlc::Stream*) + 408\n  [bt] (7) 8   libxgboost.dylib                    0x000000011f687b78 XGBoosterUnserializeFromBuffer + 168\n  [bt] (8) 9   _ctypes.cpython-37m-darwin.so       0x0000000103d81177 ffi_call_unix64 + 79\n\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_name=\"Montreal\"\n",
    "model_vars= pickle.load(open(\"../../models/\"+model_name+\".dat\",'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from alibi_detect.cd import TabularDrift\n",
    "cd = TabularDrift(p_val=0.05, X_ref=X_ref, categories_per_feature={0: None, 3: None})\n",
    "preds_drift = cd.predict(X, drift_type='batch', return_p_val=True, return_distance=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost\n",
    "import pickle\n",
    "\n",
    "# load data\n",
    "\n",
    "# split data into X and y\n",
    "X = [0,1,2,3]\n",
    "Y = [0,0,0,0]\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"model.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import platform as pf\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "#packages for time series\n",
    "import warnings\n",
    "import itertools    \n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Richard was here\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import stats\n",
    "import click\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:n_test], data[n_test:]\n",
    "\n",
    "def get_data(filename):\n",
    "    df = pd.read_csv('../../data/processed/'+filename)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "file_name=\"Montreal.csv\"\n",
    "df = get_data(file_name)\n",
    "df['datetime'] = df['datetime'].astype('datetime64[ns]')\n",
    "\n",
    "\n",
    "weather_df = df[['datetime', 'Temperature']].set_index('datetime')\n",
    "ml_df = pd.DataFrame({'Temperature': weather_df['Temperature']}, index = weather_df.index)\n",
    "\n",
    "# CREATE LAGGED ATTRIBUTES\n",
    "\n",
    "ml_df['date'] = ml_df.index\n",
    "ml_df['month'] = ml_df['date'].dt.day\n",
    "ml_df['month'] = ml_df['date'].dt.month\n",
    "ml_df['year'] = ml_df['date'].dt.year\n",
    "\n",
    "ml_df['lag1'] = ml_df['Temperature'].shift(periods=1, fill_value=0)\n",
    "ml_df['lag2'] = ml_df['Temperature'].shift(periods=2, fill_value=0)\n",
    "ml_df['lag12'] = ml_df['Temperature'].shift(periods=12, fill_value=0)\n",
    "ml_df['lag24'] = ml_df['Temperature'].shift(periods=24, fill_value=0)\n",
    "\n",
    "ml_df['avg_returns'] = 0\n",
    "for i in range(1, len(ml_df)):\n",
    "    ml_df['avg_returns'][i] = ml_df['lag1'][:i + 1].mean()\n",
    "\n",
    "ml_df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "# we have to eliminate all those with 0s\n",
    "ml_df = ml_df[ml_df['lag24'] != 0]\n",
    "X = ml_df.iloc[:,1:]\n",
    "y = ml_df[['Temperature']]\n",
    "split_len = int(len(weather_df)*0.80)\n",
    "\n",
    "X_train, X_test = train_test_split(X, split_len)\n",
    "y_train, y_test = train_test_split(y, split_len)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_scaled)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_scaled)\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=1000)\n",
    "xgb_model.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "              early_stopping_rounds=50,\n",
    "              verbose=False)\n",
    "\n",
    "import pickle\n",
    "print(\"DONE\")\n",
    "pickle.dump(xgb_model, open(\"../../models/\"+model_name+\".pkl\", 'wb'))\n",
    "pickle.dump(xgb_model, open(\"../../models/\"+model_name+\"transformer.pkl\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecast = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag12</th>\n",
       "      <th>lag24</th>\n",
       "      <th>avg_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-02 13:00:00</th>\n",
       "      <td>286.13686</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>286.123721</td>\n",
       "      <td>286.110581</td>\n",
       "      <td>285.979185</td>\n",
       "      <td>285.830000</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02 14:00:00</th>\n",
       "      <td>286.15000</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>286.136860</td>\n",
       "      <td>286.123721</td>\n",
       "      <td>285.992325</td>\n",
       "      <td>285.834650</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02 15:00:00</th>\n",
       "      <td>287.55000</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>286.150000</td>\n",
       "      <td>286.136860</td>\n",
       "      <td>286.005465</td>\n",
       "      <td>285.847790</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02 16:00:00</th>\n",
       "      <td>288.14000</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>287.550000</td>\n",
       "      <td>286.150000</td>\n",
       "      <td>286.018604</td>\n",
       "      <td>285.860929</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02 17:00:00</th>\n",
       "      <td>288.69000</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>288.140000</td>\n",
       "      <td>287.550000</td>\n",
       "      <td>286.031744</td>\n",
       "      <td>285.874069</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>275.13000</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>276.450000</td>\n",
       "      <td>276.150000</td>\n",
       "      <td>275.380000</td>\n",
       "      <td>273.750000</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 21:00:00</th>\n",
       "      <td>274.13000</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>275.130000</td>\n",
       "      <td>276.450000</td>\n",
       "      <td>277.450000</td>\n",
       "      <td>274.050000</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>273.48000</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>274.130000</td>\n",
       "      <td>275.130000</td>\n",
       "      <td>278.770000</td>\n",
       "      <td>274.050000</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 23:00:00</th>\n",
       "      <td>272.48000</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>273.480000</td>\n",
       "      <td>274.130000</td>\n",
       "      <td>278.480000</td>\n",
       "      <td>279.057000</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 00:00:00</th>\n",
       "      <td>271.80000</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>272.480000</td>\n",
       "      <td>273.480000</td>\n",
       "      <td>277.450000</td>\n",
       "      <td>274.730000</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45228 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Temperature  month  year        lag1        lag2  \\\n",
       "datetime                                                                \n",
       "2012-10-02 13:00:00    286.13686     10  2012  286.123721  286.110581   \n",
       "2012-10-02 14:00:00    286.15000     10  2012  286.136860  286.123721   \n",
       "2012-10-02 15:00:00    287.55000     10  2012  286.150000  286.136860   \n",
       "2012-10-02 16:00:00    288.14000     10  2012  287.550000  286.150000   \n",
       "2012-10-02 17:00:00    288.69000     10  2012  288.140000  287.550000   \n",
       "...                          ...    ...   ...         ...         ...   \n",
       "2017-11-29 20:00:00    275.13000     11  2017  276.450000  276.150000   \n",
       "2017-11-29 21:00:00    274.13000     11  2017  275.130000  276.450000   \n",
       "2017-11-29 22:00:00    273.48000     11  2017  274.130000  275.130000   \n",
       "2017-11-29 23:00:00    272.48000     11  2017  273.480000  274.130000   \n",
       "2017-11-30 00:00:00    271.80000     11  2017  272.480000  273.480000   \n",
       "\n",
       "                          lag12       lag24  avg_returns  \n",
       "datetime                                                  \n",
       "2012-10-02 13:00:00  285.979185  285.830000          274  \n",
       "2012-10-02 14:00:00  285.992325  285.834650          274  \n",
       "2012-10-02 15:00:00  286.005465  285.847790          275  \n",
       "2012-10-02 16:00:00  286.018604  285.860929          275  \n",
       "2012-10-02 17:00:00  286.031744  285.874069          276  \n",
       "...                         ...         ...          ...  \n",
       "2017-11-29 20:00:00  275.380000  273.750000          280  \n",
       "2017-11-29 21:00:00  277.450000  274.050000          280  \n",
       "2017-11-29 22:00:00  278.770000  274.050000          280  \n",
       "2017-11-29 23:00:00  278.480000  279.057000          280  \n",
       "2017-11-30 00:00:00  277.450000  274.730000          280  \n",
       "\n",
       "[45228 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bit4ada4739344a444e86dc35e0d095141c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
